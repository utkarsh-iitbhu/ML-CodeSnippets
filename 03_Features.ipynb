{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering \n",
    "**It can be classified into 4 forms:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Transformation:**\n",
    "\n",
    "- a. Missing Value Imputation\n",
    "    - Simple Imputation\n",
    "    - Mean/Median/Mode Imputation\n",
    "    - Forward/Backward Fill\n",
    "    - Interpolation Methods (Linear, Polynomial, Spline)\n",
    "    - K-Nearest Neighbors (KNN) Imputation\n",
    "    - Predictive Modeling (e.g., Regression Models)\n",
    "\n",
    "- b. Handling Categorical Features\n",
    "    - One-Hot Encoding\n",
    "    - Label Encoding\n",
    "    - Ordinal Encoding\n",
    "    - Binary Encoding\n",
    "    - Target Encoding\n",
    "    - Frequency Encoding\n",
    "\n",
    "- c. Outlier Detection\n",
    "    - Z-Score\n",
    "    - IQR (Interquartile Range)\n",
    "    - Modified Z-Score\n",
    "    - DBScan Clustering\n",
    "    - Isolation Forest\n",
    "    - Local Outlier Factor(LOF)\n",
    "\n",
    "- d. Feature Scaling\n",
    "    - Standard Scaler(Z-score Normalized)\n",
    "    - MinMax Scaler\n",
    "    - Max Abs Scaler\n",
    "    - Robust Scaler\n",
    "\n",
    "- e. Data Transformation\n",
    "    - Log Transform\n",
    "    - Box-Cox Transform\n",
    "    - Yeo-Johnson Transform\n",
    "    - Quantile Transform\n",
    "\n",
    "**2. Feature Construction:**\n",
    "\n",
    "- Date Features (Year, Month, Day, Hour, Minute, Second)\n",
    "- Time Series Decomposition (Trend, Seasonality, Residuals)\n",
    "- Rolling Window Statistics (Mean, Median, Std Dev)\n",
    "- Lag Features\n",
    "- Aggregation Features\n",
    "- Domain Specific Features\n",
    "\n",
    "**3. Feature Selection:**\n",
    "\n",
    "- a. Filter Methods\n",
    "    - Correlation-based Selection\n",
    "    - Chi-Square Test\n",
    "    - ANOVA F-Test\n",
    "    - Mutual Information\n",
    "\n",
    "- b. Wrapper Methods\n",
    "    - Recursive Feature Elimination (RFE)\n",
    "    - Forward/Backward Selection\n",
    "\n",
    "- c. Embedded Methods\n",
    "    - Lasso Regularization\n",
    "    - Ridge Regularization\n",
    "    - Random Forest Importance\n",
    "\n",
    "- d. Dimensionality Reduction Techniques\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Linear Discriminant Analysis (LDA)\n",
    "    - t-SNE\n",
    "\n",
    "**4. Feature Extraction:**\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- Kernel PCA\n",
    "- t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "- Uniform Manifold Approximation and Projection (UMAP)\n",
    "-  Independent Component Analysis (ICA)\n",
    "- Non-negative Matrix Factorization (NMF)\n",
    "- Singular Value Decomposition (SVD)\n",
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Feature Transformation**\n",
    "- a. Missing Value Imputation\n",
    "\n",
    "*These snippets assume you're working with a single column. For multiple columns, you might need to adjust the code accordingly.*\n",
    "\n",
    "*When fitting missing value we can check for the distribution wether the distribution remains the same or not.*\n",
    "\n",
    "*For categorical variables, you might want to use mode imputation or create a new category for missing values.*\n",
    "\n",
    "*Apply a GridSearchCV for different params of imputation to find out which imputation is giving the best result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer  \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "df['column'] = df['Age']\n",
    "\n",
    "# Simple Imputation\n",
    "# Mean Imputation: Replaces missing values with the mean of the column\n",
    "df['column'].fillna(df['column'].mean(), inplace=True)\n",
    "\n",
    "# Median Imputation: Replaces missing values with the median of the column\n",
    "df['column'].fillna(df['column'].median(), inplace=True)\n",
    "\n",
    "# Mode Imputation: Replaces missing values with the most frequent value (mode) of the column\n",
    "df['column'].fillna(df['column'].mode()[0], inplace=True)\n",
    "\n",
    "# Forward Fill: Replaces missing values with the previous value in the column\n",
    "df['column'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Backward Fill: Replaces missing values with the next value in the column\n",
    "df['column'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Interpolation Methods\n",
    "# Linear Interpolation: Estimates missing values using a straight line between known values\n",
    "df['column'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Polynomial Interpolation: Estimates missing values using a polynomial function (curved line) of specified order\n",
    "df['column'].interpolate(method='polynomial', order=2, inplace=True)\n",
    "\n",
    "# Spline Interpolation: Estimates missing values using a piecewise polynomial function for a smooth curve\n",
    "df['column'].interpolate(method='spline', order=2, inplace=True)\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Imputation: Replaces missing values using the mean value of the nearest neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df['column'] = imputer.fit_transform(df[['column']])\n",
    "\n",
    "# Predictive Modeling (using IterativeImputer, which uses regression): \n",
    "# Estimates missing values using predictive modeling with iterative regression\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "df['column'] = imputer.fit_transform(df[['column']])\n",
    "\n",
    "# Using SimpleImputer for basic strategies\n",
    "# Replaces missing values using specified strategy ('mean', 'median', 'most_frequent', 'constant')\n",
    "imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent', 'constant'\n",
    "df['column'] = imputer.fit_transform(df[['column']])\n",
    "\n",
    "# Multiple Imputation (using IterativeImputer multiple times): Creates multiple imputations and averages the results\n",
    "n_imputations = 5\n",
    "imputed_data = []\n",
    "for i in range(n_imputations):\n",
    "    imputer = IterativeImputer(random_state=i)\n",
    "    imputed_data.append(imputer.fit_transform(df))\n",
    "\n",
    "# Average the imputations\n",
    "df_imputed = pd.DataFrame(np.mean(imputed_data, axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b. Handling Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# One-Hot Encoding: Converts categories to binary vectors\n",
    "onehot = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot.fit_transform(df[['categorical_column']])\n",
    "onehot_df = pd.DataFrame(onehot_encoded, columns=onehot.get_feature_names(['categorical_column']))\n",
    "\n",
    "# Label Encoding: Assigns unique integer to each category\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['categorical_column'])\n",
    "\n",
    "# Ordinal Encoding: Assigns integers to categories with order\n",
    "oe = OrdinalEncoder()\n",
    "df['ordinal_encoded'] = oe.fit_transform(df[['categorical_column']])\n",
    "\n",
    "# Target Encoding: Replaces categories with mean of the target variable\n",
    "target_mean = df.groupby('categorical_column')['target'].mean()\n",
    "df['target_encoded'] = df['categorical_column'].map(target_mean)\n",
    "\n",
    "# Frequency Encoding: Replaces categories with their frequency\n",
    "freq_encoding = df['categorical_column'].value_counts(normalize=True)\n",
    "df['freq_encoded'] = df['categorical_column'].map(freq_encoding)\n",
    "\n",
    "# K-Bins Discretization: Replaces categories with bins and places its count\n",
    "kbin_encoded = KBinsDiscretizer(n_bins=15,encode='ordinal',strategy='quantile')\n",
    "df['kbin_encoded'] = kbin_encoded.fit_transform(df[['kbin_encoded']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Z-Score: Detects outliers based on standard deviations from the mean\n",
    "z_scores = np.abs((df['column'] - df['column'].mean()) / df['column'].std())\n",
    "df['is_outlier_zscore'] = z_scores > 3\n",
    "\n",
    "# IQR: Detects outliers based on the interquartile range\n",
    "Q1 = df['column'].quantile(0.25)\n",
    "Q3 = df['column'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df['is_outlier_iqr'] = (df['column'] < (Q1 - 1.5 * IQR)) | (df['column'] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Isolation Forest: Detects outliers using an ensemble of trees\n",
    "iso_forest = IsolationForest(contamination=0.1)\n",
    "df['is_outlier_iforest'] = iso_forest.fit_predict(df[['column']])\n",
    "\n",
    "# Local Outlier Factor: Detects outliers by comparing the local density of a point to its neighbors\n",
    "lof = LocalOutlierFactor()\n",
    "df['is_outlier_lof'] = lof.fit_predict(df[['column']])\n",
    "\n",
    "# DBScan Clustering: Detects outliers as points that do not belong to any cluster\n",
    "dbscan = DBSCAN(eps=3, min_samples=2)\n",
    "df['is_outlier_dbscan'] = dbscan.fit_predict(df[['column']])\n",
    "df['is_outlier_dbscan'] = df['is_outlier_dbscan'] == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "\n",
    "# Standard Scaler: Scales features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "df['scaled_standard'] = scaler.fit_transform(df[['column']])\n",
    "\n",
    "# MinMax Scaler: Scales features to a given range (default is 0 to 1)\n",
    "scaler = MinMaxScaler()\n",
    "df['scaled_minmax'] = scaler.fit_transform(df[['column']])\n",
    "\n",
    "# Robust Scaler: Scales features using statistics that are robust to outliers (uses median and IQR)\n",
    "scaler = RobustScaler()\n",
    "df['scaled_robust'] = scaler.fit_transform(df[['column']])\n",
    "\n",
    "# MaxAbs Scaler: Scales features by their maximum absolute value, preserving the sign\n",
    "scaler = MaxAbsScaler()\n",
    "df['scaled_maxabs'] = scaler.fit_transform(df[['column']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- e. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "X_train,X_test=[],[]\n",
    "# Log Transform: Applies log transformation to reduce skewness | Best with outliers\n",
    "df['log_transform'] = np.log1p(df['column'])\n",
    "\n",
    "# Box-Cox Transform: Transforms data to make it more normally distributed | Sensitive to high values\n",
    "df['boxcox_transform'], _ = stats.boxcox(df['column'])\n",
    "pt = PowerTransformer(method='box-cox') # Default method: Yeo-Johnson\n",
    "X_train_transformed = pt.fit_transform(X_train+0.000001)\n",
    "X_test_transformed = pt.transform(X_test+0.000001)\n",
    "pd.DataFrame({'cols':X_train.columns,'box_cox_lambdas':pt.lambdas_})\n",
    "\n",
    "# Yeo-Johnson Transform: Transforms data to make it more normally distributed (handles zero and negative values) | Better than Box-Cox\n",
    "df['yeojohnson_transform'], _ = stats.yeojohnson(df['column'])\n",
    "\n",
    "# Quantile Transform: Transforms data to follow a uniform or normal distribution | Worst with Outliers\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "df['quantile_transform'] = qt.fit_transform(df[['column']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Feature Construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date Features: Extract year, month, day, and day of the week from date column\n",
    "df['date'] = pd.to_datetime(df['date_column'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "\n",
    "# Time Series Decomposition: Decompose time series into trend, seasonal, and residual components\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(df['time_series_column'], model='additive', period=365) # per year \n",
    "df['trend'] = result.trend\n",
    "df['seasonal'] = result.seasonal\n",
    "df['residual'] = result.resid\n",
    "\n",
    "# Rolling Window Statistics: Calculate rolling mean and standard deviation with a window of 7 days\n",
    "df['rolling_mean'] = df['column'].rolling(window=7).mean()\n",
    "df['rolling_std'] = df['column'].rolling(window=7).std()\n",
    "\n",
    "# Lag Features: Create lag features for previous periods\n",
    "df['lag_1'] = df['column'].shift(1)\n",
    "df['lag_7'] = df['column'].shift(7)\n",
    "\n",
    "# Aggregation Features: Compute mean and sum based on categories\n",
    "df['mean_by_category'] = df.groupby('category')['value'].transform('mean')\n",
    "df['sum_by_category'] = df.groupby('category')['value'].transform('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer, KNNImputer  \n",
    "\n",
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "# Convert categorical columns to one-hot encoded format\n",
    "df_encoded = pd.get_dummies(df[['Sex', 'Embarked']])\n",
    "# Join the encoded columns back to the original DataFrame\n",
    "df = df.join(df_encoded).drop(['Sex', 'Embarked'], axis=1)\n",
    "predicted = 'Survived'\n",
    "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# K-Nearest Neighbors (KNN) Imputation: Replaces missing values using the mean value of the nearest neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df['Age'] = imputer.fit_transform(df[['Age']])\n",
    "X = df.drop(predicted,axis=1)\n",
    "y = df[predicted]\n",
    "\n",
    "# Filter Methods\n",
    "# Correlation-based Selection: Select features with high absolute correlation with the target\n",
    "# Works well for continuous features to identify those strongly correlated with the target\n",
    "correlation = df.corr(numeric_only=True)['Survived'].abs().sort_values(ascending=False)\n",
    "selected_features_corr = correlation[correlation > 0.1].index.tolist()\n",
    "\n",
    "# Chi-Square Test: Select features based on chi-square statistical test\n",
    "# Suitable for categorical features; it assesses independence between features and target\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "selected_features_chi2 = X.columns[selector.get_support()]\n",
    "\n",
    "# ANOVA F-Test: Select features based on F-statistic from ANOVA test\n",
    "# Used for continuous features in regression tasks; it measures the relationship between features and target\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X_new_f = selector.fit_transform(X, y)\n",
    "selected_features_f = X.columns[selector.get_support()]\n",
    "\n",
    "# Mutual Information: Select features based on mutual information between features and target\n",
    "# Captures non-linear relationships between features and target; works with both categorical and continuous features\n",
    "selector = SelectKBest(mutual_info_regression, k=10)\n",
    "X_new_mi = selector.fit_transform(X, y)\n",
    "selected_features_mi = X.columns[selector.get_support()]\n",
    "\n",
    "# Wrapper Methods\n",
    "# Recursive Feature Elimination (RFE): Select features using a model to recursively eliminate least important features\n",
    "# Uses a model to recursively select features based on performance, suitable for any feature type\n",
    "rfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=10)\n",
    "X_new_rfe = rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[rfe.support_]\n",
    "\n",
    "# Embedded Methods\n",
    "# Lasso: Select features based on Lasso regression (features with non-zero coefficients)\n",
    "# Regularization technique that performs feature selection by shrinking some coefficients to zero; works well with continuous features\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "selected_features_lasso = X.columns[lasso.coef_ != 0]\n",
    "\n",
    "# Random Forest Importance: Select features based on feature importance from Random Forest\n",
    "# Provides feature importance scores from a Random Forest model; useful for both continuous and categorical features\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_})\n",
    "selected_features_rf = importances.nlargest(2, 'importance')['feature']  # Adjust n as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA, NMF\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "# Reduces dimensionality by projecting data onto the directions of maximum variance.\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "# Reduces dimensionality by maximizing the separation between multiple classes.\n",
    "lda = LinearDiscriminantAnalysis(n_components=10)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Kernel PCA\n",
    "# Extends PCA to non-linear dimensionality reduction using kernel methods.\n",
    "kpca = KernelPCA(n_components=10, kernel='rbf')\n",
    "X_kpca = kpca.fit_transform(X)\n",
    "\n",
    "# t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "# Reduces dimensionality while preserving local structure, typically used for visualization.\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Non-negative Matrix Factorization (NMF)\n",
    "# Factorizes the matrix into non-negative matrices, useful for extracting parts-based representations.\n",
    "nmf = NMF(n_components=10)\n",
    "X_nmf = nmf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from faker import Faker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Faker for generating dummy data\n",
    "fake = Faker()\n",
    "\n",
    "# Create dummy data\n",
    "data = {\n",
    "    'age': np.random.randint(18, 70, size=10),  # Random ages between 18 and 70\n",
    "    'income': np.random.randint(20000, 100000, size=10),  # Random incomes between $20,000 and $100,000\n",
    "    'credit_score': np.random.randint(300, 850, size=10),  # Random credit scores between 300 and 850\n",
    "    'gender': np.random.choice(['Male', 'Female'], size=10),  # Random genders\n",
    "    'occupation': np.random.choice(['Engineer', 'Doctor', 'Artist', 'Teacher', 'Nurse'], size=10),  # Random occupations\n",
    "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], size=10),  # Random cities\n",
    "    'transaction_date': [fake.date_this_decade() for _ in range(10)],  # Random dates within this decade\n",
    "    'description': [fake.sentence() for _ in range(10)],  # Random text descriptions\n",
    "    'target': np.random.choice([0, 1], size=10)  # Random binary target values\n",
    "}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.shape)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "# Define column types\n",
    "numeric_features = ['age', 'income', 'credit_score']\n",
    "categorical_features = ['gender', 'occupation', 'city']\n",
    "date_features = ['transaction_date']\n",
    "text_features = ['description']\n",
    "\n",
    "# Custom transformer for Isolation Forest outlier removal\n",
    "class IsolationForestOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, contamination=0.1):\n",
    "        self.contamination = contamination\n",
    "        self.isolation_forest = IsolationForest(contamination=self.contamination, random_state=0)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.isolation_forest.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        outliers = self.isolation_forest.predict(X) == -1\n",
    "        return X[~outliers]\n",
    "\n",
    "# 1. Feature Transformation Pipeline\n",
    "feature_transformation = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')), # Imputer for missing values\n",
    "        # ('outlier_remover', IsolationForestOutlierRemover()), # Outlier Removal, can use crafted classes as well\n",
    "        ('yeo_johnson', PowerTransformer(method='yeo-johnson')), # Transformation\n",
    "        ('scaler', MinMaxScaler())  # Scaling \n",
    "    ]), numeric_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_features)\n",
    "])\n",
    "\n",
    "# 2. Feature Construction Pipeline\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['year'] = pd.to_datetime(X['transaction_date']).dt.year\n",
    "        X['month'] = pd.to_datetime(X['transaction_date']).dt.month\n",
    "        X['day_of_week'] = pd.to_datetime(X['transaction_date']).dt.dayofweek\n",
    "        return X[['year', 'month', 'day_of_week']]\n",
    "\n",
    "class TextFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['word_count'] = X['description'].str.split().str.len()\n",
    "        X['char_count'] = X['description'].str.len()\n",
    "        return X[['word_count', 'char_count']]\n",
    "\n",
    "feature_construction = ColumnTransformer([\n",
    "    ('date', DateFeatureExtractor(), date_features),\n",
    "    ('text', TextFeatureExtractor(), text_features)\n",
    "])\n",
    "\n",
    "# 3. Feature Selection Pipeline\n",
    "feature_selection = ColumnTransformer([\n",
    "    ('num_select_best', Pipeline([\n",
    "        ('select_best', SelectKBest(f_regression, k=5))\n",
    "    ]), numeric_features),\n",
    "    ('cat_select_best', Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('select_best', SelectKBest(chi2, k=5))\n",
    "    ]), categorical_features),\n",
    "    \n",
    "])\n",
    "\n",
    "# 4. Feature Extraction Pipeline\n",
    "feature_extraction = ColumnTransformer([\n",
    "    ('num_pca', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),  # Impute missing values\n",
    "        ('scaler', StandardScaler()),  # Scale the features\n",
    "        ('pca', PCA(n_components=2))  # Apply PCA\n",
    "    ]), numeric_features),\n",
    "    ('cat_pca', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('pca', PCA(n_components=2))  # Apply PCA\n",
    "    ]), categorical_features)\n",
    "])\n",
    "\n",
    "# Combine all pipelines\n",
    "final_pipeline = FeatureUnion([\n",
    "    ('transformation', feature_transformation),\n",
    "    ('construction', feature_construction),\n",
    "    ('selection', feature_selection),\n",
    "    ('extraction', feature_extraction)\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('features', final_pipeline),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Prepare data for training\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit and predict\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "predictions = full_pipeline.predict(X_test)\n",
    "\n",
    "# Display predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from faker import Faker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize Faker for generating dummy data\n",
    "fake = Faker()\n",
    "\n",
    "# Create dummy data\n",
    "data = {\n",
    "    'age': np.random.randint(18, 70, size=10),  # Random ages between 18 and 70\n",
    "    'income': np.random.randint(20000, 100000, size=10),  # Random incomes between $20,000 and $100,000\n",
    "    'credit_score': np.random.randint(300, 850, size=10),  # Random credit scores between 300 and 850\n",
    "    'gender': np.random.choice(['Male', 'Female'], size=10),  # Random genders\n",
    "    'occupation': np.random.choice(['Engineer', 'Doctor', 'Artist', 'Teacher', 'Nurse'], size=10),  # Random occupations\n",
    "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], size=10),  # Random cities\n",
    "    'transaction_date': [fake.date_this_decade() for _ in range(10)],  # Random dates within this decade\n",
    "    'description': [fake.sentence() for _ in range(10)],  # Random text descriptions\n",
    "    'target': np.random.choice([0, 1], size=10)  # Random binary target values\n",
    "}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.shape)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "# Define column types\n",
    "numeric_features = ['age', 'income', 'credit_score']\n",
    "categorical_features = ['gender', 'occupation', 'city']\n",
    "date_features = ['transaction_date']\n",
    "text_features = ['description']\n",
    "\n",
    "# Custom transformer for Isolation Forest outlier removal\n",
    "class IsolationForestOutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, contamination=0.1):\n",
    "        self.contamination = contamination\n",
    "        self.isolation_forest = IsolationForest(contamination=self.contamination, random_state=0)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.isolation_forest.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        outliers = self.isolation_forest.predict(X) == -1\n",
    "        return X[~outliers]\n",
    "\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['year'] = pd.to_datetime(X['transaction_date']).dt.year\n",
    "        X['month'] = pd.to_datetime(X['transaction_date']).dt.month\n",
    "        X['day_of_week'] = pd.to_datetime(X['transaction_date']).dt.dayofweek\n",
    "        return X[['year', 'month', 'day_of_week']]\n",
    "\n",
    "class TextFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['word_count'] = X['description'].str.split().str.len()\n",
    "        X['char_count'] = X['description'].str.len()\n",
    "        return X[['word_count', 'char_count']]\n",
    "\n",
    "\n",
    "# 1. Feature Transformation Pipeline\n",
    "feature_transformation = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')), # Imputer for missing values\n",
    "        # ('outlier_remover', IsolationForestOutlierRemover()), # Outlier Removal, can use crafted classes as well\n",
    "        ('yeo_johnson', PowerTransformer(method='yeo-johnson')), # Transformation\n",
    "        ('scaler', MinMaxScaler()),  # Scaling \n",
    "        ('select_best', SelectKBest(f_regression, k=3)),\n",
    "        ('pca', PCA(n_components=2)) \n",
    "    ]), numeric_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('select_best', SelectKBest(chi2, k=3)),\n",
    "        ('pca', PCA(n_components=2)) \n",
    "    ]), categorical_features),\n",
    "    ('date_ft',Pipeline([  \n",
    "        ('date', DateFeatureExtractor()),\n",
    "        # ('lda',LinearDiscriminantAnalysis(n_components=2)),\n",
    "    ]),date_features ),\n",
    "     ('text', TextFeatureExtractor(), text_features),\n",
    "])\n",
    "\n",
    "pipeline_new = Pipeline([\n",
    "    ('features', feature_transformation),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Prepare data for training\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit and predict\n",
    "pipeline_new.fit(X_train, y_train)\n",
    "predictions_new = pipeline_new.predict(X_test)\n",
    "\n",
    "# Display predictions\n",
    "print(predictions_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Feature Transformation:\n",
      "[[ 1.41913746e-01  2.49718014e-01  6.49804158e-01  3.43092076e-01\n",
      "   2.02000000e+03  9.00000000e+00  1.00000000e+00  3.00000000e+00\n",
      "   1.80000000e+01]\n",
      " [-6.45828653e-01  4.13573284e-01  6.49804158e-01  3.43092076e-01\n",
      "   2.02200000e+03  4.00000000e+00  4.00000000e+00  4.00000000e+00\n",
      "   3.50000000e+01]\n",
      " [-5.89996829e-01 -3.28468791e-01 -6.60175386e-01  1.91251947e-01\n",
      "   2.02400000e+03  1.00000000e+00  0.00000000e+00  7.00000000e+00\n",
      "   3.90000000e+01]\n",
      " [ 6.55706104e-01  4.74995477e-01 -5.16052717e-02 -3.67737824e-01\n",
      "   2.02200000e+03  3.00000000e+00  4.00000000e+00  3.00000000e+00\n",
      "   2.10000000e+01]\n",
      " [ 1.84520834e-01 -5.04404370e-01 -5.16052717e-02 -3.67737824e-01\n",
      "   2.02200000e+03  5.00000000e+00  3.00000000e+00  5.00000000e+00\n",
      "   3.40000000e+01]\n",
      " [ 4.82128965e-01 -1.38310644e-01  6.49804158e-01  3.43092076e-01\n",
      "   2.02300000e+03  5.00000000e+00  6.00000000e+00  5.00000000e+00\n",
      "   3.00000000e+01]\n",
      " [-2.81788776e-01  1.80848545e-01 -5.16052717e-02 -3.67737824e-01\n",
      "   2.02200000e+03  1.00000000e+01  1.00000000e+00  6.00000000e+00\n",
      "   4.20000000e+01]\n",
      " [-4.16249950e-01 -6.68743219e-02 -1.03121073e+00  6.18160942e-01\n",
      "   2.02400000e+03  1.00000000e+00  5.00000000e+00  8.00000000e+00\n",
      "   4.60000000e+01]\n",
      " [ 3.98303143e-01 -2.16121271e-01 -5.16052717e-02 -3.67737824e-01\n",
      "   2.02300000e+03  9.00000000e+00  1.00000000e+00  6.00000000e+00\n",
      "   3.60000000e+01]\n",
      " [ 7.12914154e-02 -6.49559227e-02 -5.16052717e-02 -3.67737824e-01\n",
      "   2.02000000e+03  1.00000000e+00  5.00000000e+00  4.00000000e+00\n",
      "   2.10000000e+01]]\n",
      "Shape: (10, 9)\n"
     ]
    }
   ],
   "source": [
    "# Apply Feature Transformation\n",
    "# Check the output of each pipeline step\n",
    "transformed_data = feature_transformation.fit_transform(X,y)\n",
    "print(\"Data after Feature Transformation:\")\n",
    "print(transformed_data)\n",
    "print(\"Shape:\", transformed_data.shape)\n",
    "\n",
    "# # Apply Feature Construction\n",
    "# constructed_data = feature_construction.fit_transform(X)\n",
    "# constructed_df = pd.DataFrame(constructed_data, columns=['year', 'month', 'day_of_week', 'word_count', 'char_count'])\n",
    "# print(\"Data after Feature Construction:\")\n",
    "# print(constructed_df.head())\n",
    "# print(\"Shape:\", constructed_df.shape)\n",
    "\n",
    "# # Apply Feature Selection\n",
    "# selected_data = feature_selection.fit_transform(X, y)\n",
    "# selected_df = pd.DataFrame(selected_data)\n",
    "# print(\"Data after Feature Selection:\")\n",
    "# print(selected_df.head())\n",
    "# print(\"Shape:\", selected_df.shape)\n",
    "\n",
    "# # Apply Feature Extraction\n",
    "# extracted_data = feature_extraction.fit_transform(X)\n",
    "# extracted_df = pd.DataFrame(extracted_data, columns=[f'component_{i}' for i in range(extracted_data.shape[1])])\n",
    "# print(\"Data after Feature Extraction:\")\n",
    "# print(extracted_df.head())\n",
    "# print(\"Shape:\", extracted_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print your pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;yeo_johnson&#x27;,\n",
       "                                                                   PowerTransformer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  (&#x27;select_best&#x27;,\n",
       "                                                                   SelectKBest(k=3,\n",
       "                                                                               score_func=&lt;function f_regression at 0x000001DDD42ADC60&gt;)),\n",
       "                                                                  (&#x27;pca&#x27;,\n",
       "                                                                   PCA(n_components=2))]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;income&#x27;,\n",
       "                                                   &#x27;credit_score&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipe...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                                                  (&#x27;select_best&#x27;,\n",
       "                                                                   SelectKBest(k=3,\n",
       "                                                                               score_func=&lt;function chi2 at 0x000001DDD42ADA20&gt;)),\n",
       "                                                                  (&#x27;pca&#x27;,\n",
       "                                                                   PCA(n_components=2))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;occupation&#x27;,\n",
       "                                                   &#x27;city&#x27;]),\n",
       "                                                 (&#x27;date_ft&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;date&#x27;,\n",
       "                                                                   DateFeatureExtractor())]),\n",
       "                                                  [&#x27;transaction_date&#x27;]),\n",
       "                                                 (&#x27;text&#x27;,\n",
       "                                                  TextFeatureExtractor(),\n",
       "                                                  [&#x27;description&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;yeo_johnson&#x27;,\n",
       "                                                                   PowerTransformer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  (&#x27;select_best&#x27;,\n",
       "                                                                   SelectKBest(k=3,\n",
       "                                                                               score_func=&lt;function f_regression at 0x000001DDD42ADC60&gt;)),\n",
       "                                                                  (&#x27;pca&#x27;,\n",
       "                                                                   PCA(n_components=2))]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;income&#x27;,\n",
       "                                                   &#x27;credit_score&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipe...\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                                                  (&#x27;select_best&#x27;,\n",
       "                                                                   SelectKBest(k=3,\n",
       "                                                                               score_func=&lt;function chi2 at 0x000001DDD42ADA20&gt;)),\n",
       "                                                                  (&#x27;pca&#x27;,\n",
       "                                                                   PCA(n_components=2))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;occupation&#x27;,\n",
       "                                                   &#x27;city&#x27;]),\n",
       "                                                 (&#x27;date_ft&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;date&#x27;,\n",
       "                                                                   DateFeatureExtractor())]),\n",
       "                                                  [&#x27;transaction_date&#x27;]),\n",
       "                                                 (&#x27;text&#x27;,\n",
       "                                                  TextFeatureExtractor(),\n",
       "                                                  [&#x27;description&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;features: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for features: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;yeo_johnson&#x27;,\n",
       "                                                  PowerTransformer()),\n",
       "                                                 (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                                                 (&#x27;select_best&#x27;,\n",
       "                                                  SelectKBest(k=3,\n",
       "                                                              score_func=&lt;function f_regression at 0x000001DDD42ADC60&gt;)),\n",
       "                                                 (&#x27;pca&#x27;, PCA(n_components=2))]),\n",
       "                                 [&#x27;age&#x27;, &#x27;income&#x27;, &#x27;credit_score&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  Simpl...ing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                                 (&#x27;select_best&#x27;,\n",
       "                                                  SelectKBest(k=3,\n",
       "                                                              score_func=&lt;function chi2 at 0x000001DDD42ADA20&gt;)),\n",
       "                                                 (&#x27;pca&#x27;, PCA(n_components=2))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;occupation&#x27;, &#x27;city&#x27;]),\n",
       "                                (&#x27;date_ft&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;date&#x27;,\n",
       "                                                  DateFeatureExtractor())]),\n",
       "                                 [&#x27;transaction_date&#x27;]),\n",
       "                                (&#x27;text&#x27;, TextFeatureExtractor(),\n",
       "                                 [&#x27;description&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age&#x27;, &#x27;income&#x27;, &#x27;credit_score&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PowerTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.PowerTransformer.html\">?<span>Documentation for PowerTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PowerTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SelectKBest<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.SelectKBest.html\">?<span>Documentation for SelectKBest</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SelectKBest(k=3, score_func=&lt;function f_regression at 0x000001DDD42ADC60&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=2)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;occupation&#x27;, &#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SelectKBest<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.SelectKBest.html\">?<span>Documentation for SelectKBest</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SelectKBest(k=3, score_func=&lt;function chi2 at 0x000001DDD42ADA20&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=2)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">date_ft</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;transaction_date&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">DateFeatureExtractor</label><div class=\"sk-toggleable__content fitted\"><pre>DateFeatureExtractor()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">text</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;description&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TextFeatureExtractor</label><div class=\"sk-toggleable__content fitted\"><pre>TextFeatureExtractor()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('yeo_johnson',\n",
       "                                                                   PowerTransformer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  ('select_best',\n",
       "                                                                   SelectKBest(k=3,\n",
       "                                                                               score_func=<function f_regression at 0x000001DDD42ADC60>)),\n",
       "                                                                  ('pca',\n",
       "                                                                   PCA(n_components=2))]),\n",
       "                                                  ['age', 'income',\n",
       "                                                   'credit_score']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipe...\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                  ('select_best',\n",
       "                                                                   SelectKBest(k=3,\n",
       "                                                                               score_func=<function chi2 at 0x000001DDD42ADA20>)),\n",
       "                                                                  ('pca',\n",
       "                                                                   PCA(n_components=2))]),\n",
       "                                                  ['gender', 'occupation',\n",
       "                                                   'city']),\n",
       "                                                 ('date_ft',\n",
       "                                                  Pipeline(steps=[('date',\n",
       "                                                                   DateFeatureExtractor())]),\n",
       "                                                  ['transaction_date']),\n",
       "                                                 ('text',\n",
       "                                                  TextFeatureExtractor(),\n",
       "                                                  ['description'])])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_new.fit(X_train, y_train) # type: ignore\n",
    "# full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': FeatureUnion(transformer_list=[('transformation',\n",
       "                                 ColumnTransformer(transformers=[('num',\n",
       "                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                                  ('yeo_johnson',\n",
       "                                                                                   PowerTransformer()),\n",
       "                                                                                  ('scaler',\n",
       "                                                                                   MinMaxScaler())]),\n",
       "                                                                  ['age',\n",
       "                                                                   'income',\n",
       "                                                                   'credit_score']),\n",
       "                                                                 ('cat',\n",
       "                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                                 strategy='constant')),\n",
       "                                                                                  ('onehot',\n",
       "                                                                                   OneH...\n",
       "                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                                  ('scaler',\n",
       "                                                                                   StandardScaler()),\n",
       "                                                                                  ('pca',\n",
       "                                                                                   PCA(n_components=2))]),\n",
       "                                                                  ['age',\n",
       "                                                                   'income',\n",
       "                                                                   'credit_score']),\n",
       "                                                                 ('cat_pca',\n",
       "                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                                 strategy='constant')),\n",
       "                                                                                  ('onehot',\n",
       "                                                                                   OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                                  ('pca',\n",
       "                                                                                   PCA(n_components=2))]),\n",
       "                                                                  ['gender',\n",
       "                                                                   'occupation',\n",
       "                                                                   'city'])]))]),\n",
       " 'classifier': LogisticRegression()}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.named_steps\n",
    "# pipeline_new.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Cross-Validation for better check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "# cross validation using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(full_pipeline, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "cross_val_score(pipeline_new, X_train, y_train, cv=5, scoring='accuracy').mean() # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickle your pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import pickle\n",
    "pickle.dump(full_pipeline,open('./output/pipeline_feature.pkl','wb'))\n",
    "pickle.dump(pipeline_new,open('./output/pipeline_feature2.pkl','wb')) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline prediction on Titanic Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest...\n",
      "RandomForest Accuracy: 0.8212\n",
      "RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       105\n",
      "           1       0.80      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Training LogisticRegression...\n",
      "LogisticRegression Accuracy: 0.8101\n",
      "LogisticRegression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       105\n",
      "           1       0.79      0.74      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "SVM Accuracy: 0.8156\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       105\n",
      "           1       0.81      0.73      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.81       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n",
      "\n",
      "Performing GridSearchCV for RandomForest...\n",
      "Best RandomForest score: 0.8272\n",
      "Best RandomForest params: {'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'features__selector__k': 15}\n",
      "\n",
      "Performing GridSearchCV for LogisticRegression...\n",
      "Best LogisticRegression score: 0.7963\n",
      "Best LogisticRegression params: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'features__selector__k': 15}\n",
      "\n",
      "Performing GridSearchCV for SVM...\n",
      "Best SVM score: 0.8272\n",
      "Best SVM params: {'classifier__C': 1, 'classifier__kernel': 'rbf', 'features__selector__k': 15}\n",
      "\n",
      "Overall best model: RandomForest\n",
      "Best score: 0.8272\n",
      "Best parameters: {'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'features__selector__k': 15}\n",
      "\n",
      "Best Model Performance on Test Set:\n",
      "Accuracy: 0.8156\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       105\n",
      "           1       0.83      0.70      0.76        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.80      0.80       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "# Define feature groups\n",
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "ordinal_features = ['Pclass']\n",
    "nominal_features = ['Sex', 'Embarked']\n",
    "\n",
    "# Custom transformer for feature construction\n",
    "class FeatureConstructor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Extract title from name\n",
    "        X['Title'] = X['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        # Group rare titles\n",
    "        rare_titles = ['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "        X['Title'] = X['Title'].replace(rare_titles, 'Rare')\n",
    "        # Family size\n",
    "        X['FamilySize'] = X['SibSp'] + X['Parch'] + 1\n",
    "        # Is alone\n",
    "        X['IsAlone'] = (X['FamilySize'] == 1).astype(int)\n",
    "        # Fare per person\n",
    "        X['FarePerPerson'] = X['Fare'] / X['FamilySize']\n",
    "        # Age * Class\n",
    "        X['Age*Class'] = X['Age'] * X['Pclass']\n",
    "        return X\n",
    "\n",
    "# Numeric pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Ordinal pipeline\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, nominal_features),\n",
    "        ('ord', ordinal_transformer, ordinal_features)\n",
    "    ])\n",
    "\n",
    "# Feature engineering pipeline\n",
    "feature_engineering = Pipeline([\n",
    "    ('constructor', FeatureConstructor()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', SelectKBest(f_classif, k=15))\n",
    "])\n",
    "\n",
    "# Create different classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Create the final pipeline with different models\n",
    "final_pipeline = {\n",
    "    'RandomForest': Pipeline([\n",
    "        ('features', feature_engineering),\n",
    "        ('classifier', rf_classifier)\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('features', feature_engineering),\n",
    "        ('classifier', lr_classifier)\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('features', feature_engineering),\n",
    "        ('classifier', svm_classifier)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, pipeline in final_pipeline.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"{name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Grid search for best model and parameters\n",
    "param_grid = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [5, 10, None],\n",
    "        'features__selector__k': [10, 15, 20]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'features__selector__k': [10, 15, 20]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['rbf', 'linear'],\n",
    "        'features__selector__k': [10, 15, 20]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for name, pipeline in final_pipeline.items():\n",
    "    print(f\"\\nPerforming GridSearchCV for {name}...\")\n",
    "    grid_search = GridSearchCV(pipeline, param_grid[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_score = grid_search.best_score_\n",
    "        best_model = name\n",
    "        best_params = grid_search.best_params_\n",
    "    print(f\"Best {name} score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best {name} params: {grid_search.best_params_}\")\n",
    "\n",
    "print(f\"\\nOverall best model: {best_model}\")\n",
    "print(f\"Best score: {best_score:.4f}\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_pipeline = final_pipeline[best_model].set_params(**best_params)\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "print(\"\\nBest Model Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
